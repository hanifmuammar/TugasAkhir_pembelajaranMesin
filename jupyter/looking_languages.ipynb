{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Source sentence                Target language\n",
      "0        Selamat pagi!                      Indonesia\n",
      "1        Good morning!                        Inggris\n",
      "2         Buenos días!                        Spanyol\n",
      "3             Bonjour!                       Perancis\n",
      "4        Guten Morgen!                         Jerman\n",
      "5          Buongiorno!                         Italia\n",
      "6            おはようございます     Ohayou gozaimasu)! (Jepang\n",
      "7                안녕하세요        Annyeonghaseyo)! (Korea\n",
      "8                  早上好       Zǎoshang hǎo)! (Tiongkok\n",
      "9          Доброе утро           Dobroe utro)! (Rusia\n",
      "10          صباح الخير         Sabah al-khayr)! (Arab\n",
      "11          शुभ प्रभात         Shubh Prabhat)! (India\n",
      "12            Bom dia!                       Portugal\n",
      "13           Günaydın!                          Turki\n",
      "14  Habari ya asubuhi!                        Swahili\n",
      "15     Chào buổi sáng!                        Vietnam\n",
      "16       สวัสดีตอนเช้า  Sawasdee ton chao)! (Thailand\n",
      "17            Καλημέρα             Kalimera)! (Yunani\n",
      "18            בוקר טוב            Boker tov)! (Israel\n",
      "19         God morgon!                         Swedia\n",
      "20        Dzień dobry!                       Polandia\n",
      "21          Dobrý den!                  Republik Ceko\n",
      "22     Hyvää huomenta!                      Finlandia\n",
      "23    Magandang umaga!                       Filipina\n",
      "24     Buna dimineața!                        Rumania\n",
      "25          Добро утро         Dobro utro)! (Bulgaria\n",
      "26       Selamat pagi!                       Malaysia\n",
      "27        Labas rytas!                       Lituania\n",
      "28           Kaliméra!                         Yunani\n",
      "29        Mirëmëngjes!                        Albania\n",
      "30            Bom dia!                         Brasil\n",
      "31        Buenos días!                      Argentina\n",
      "32         Goeie môre!                      Afrikaans\n",
      "33         Добро јутро          Dobro jutro)! (Serbia\n",
      "34        Buon giorno!                     San Marino\n",
      "35           Günaydın!                   Turkmenistan\n",
      "36         Բարի առավոտ         Bari aravot)! (Armenia\n",
      "37    Magandang umaga!                         Bhutan\n",
      "38      Bonan matenon!                      Esperanto\n",
      "39            Bore da!                          Welsh\n",
      "40        Dobro jutro!                        Kroasia\n",
      "41         Dobré ráno!                       Slovakia\n",
      "42        Goedemorgen!                        Belanda\n",
      "43          Goedemôre!                      Afrikaans\n",
      "44          Góðan dag!                       Islandia\n",
      "45           Gunaydin!                          Turki\n",
      "46       Guten Morgen!                        Austria\n",
      "47           Huomenta!                      Finlandia\n",
      "48         Jo reggelt!                       Hungaria\n",
      "49        Mirëmëngjes!                         Kosovo\n"
     ]
    }
   ],
   "source": [
    "# Ubah path sesuai dengan lokasi file Anda\n",
    "file_path = r\"C:\\Users\\ASUS\\OneDrive\\Documents\\jupyter\\UAS\\tatoebas_data.csv\"\n",
    "\n",
    "# Muat data Tatoeba secara manual\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Proses setiap baris untuk memisahkan kalimat dan bahasa\n",
    "data = []\n",
    "for line in lines:\n",
    "    match = re.match(r'^(.*?)\\s*\\((.*?)\\)\\s*$', line.strip())\n",
    "    if match:\n",
    "        sentence, language = match.groups()\n",
    "        data.append([sentence, language])\n",
    "\n",
    "# Konversi ke DataFrame\n",
    "df = pd.DataFrame(data, columns=['Source sentence', 'Target language'])\n",
    "\n",
    "# Tampilkan beberapa baris pertama untuk verifikasi\n",
    "print(df.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi: 0.00%\n",
      "Kalimat: \"Good morning!   \"\n",
      "Bahasa Prediksi: Inggris\n",
      "Negara Asal: England\n"
     ]
    }
   ],
   "source": [
    "# Persiapkan fitur dan target\n",
    "X = df['Source sentence']\n",
    "y = df['Target language']\n",
    "\n",
    "# Vectorize text\n",
    "vectorizer = CountVectorizer()\n",
    "X_vectorized = vectorizer.fit_transform(X)\n",
    "\n",
    "# Bagi data menjadi train dan test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Latih model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluasi model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Akurasi: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Simpan model dan vectorizer\n",
    "joblib.dump(model, 'language_prediction_model.pkl')\n",
    "joblib.dump(vectorizer, 'vectorizer.pkl')\n",
    "\n",
    "# Definisikan fungsi untuk memprediksi bahasa dan negara asal kalimat\n",
    "def predict_language_and_country(sentence):\n",
    "    sentence_vectorized = vectorizer.transform([sentence])\n",
    "    prediction = model.predict(sentence_vectorized)[0]\n",
    "    \n",
    "    # Mapping bahasa ke negara\n",
    "    language_to_country = {\n",
    "        'Indonesia': 'Indonesia',\n",
    "        'Inggris': 'England',\n",
    "        'Spanyol': 'Spain',\n",
    "        'Perancis': 'France',\n",
    "        'Jerman': 'Germany',\n",
    "        'Italia': 'Italy',\n",
    "        'Jepang': 'Japan',\n",
    "        'Korea': 'Korea',\n",
    "        'swedia' : 'sweden',\n",
    "        \n",
    "        # Tambahkan bahasa dan negara lain sesuai dengan data Anda\n",
    "    }\n",
    "    \n",
    "    country = language_to_country.get(prediction, 'Unknown')\n",
    "    return prediction, country\n",
    "\n",
    "# Prediksi bahasa dan negara untuk kalimat baru\n",
    "new_sentence = \"Good morning!   \"\n",
    "language, country = predict_language_and_country(new_sentence)\n",
    "print(f'Kalimat: \"{new_sentence}\"')\n",
    "print(f'Bahasa Prediksi: {language}')\n",
    "print(f'Negara Asal: {country}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
